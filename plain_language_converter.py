"""
å¤§ç™½è¯è½¬æ¢å¼•æ“
Plain Language Converter

åŠŸèƒ½ï¼š
1. å°†ä¸“ä¸šå‘½ç†æœ¯è¯­è½¬åŒ–ä¸ºé€šä¿—æ˜“æ‡‚çš„ç”Ÿæ´»è¯­è¨€
2. ç”¨å…·ä½“çš„ç”Ÿæ´»åœºæ™¯æ›¿ä»£æŠ½è±¡æ¦‚å¿µ
3. å°†å‘½ç†åˆ†æè½¬åŒ–ä¸ºå¿ƒç†å’Œè¡Œä¸ºæè¿°
4. ç¡®ä¿æ‰€æœ‰ç”¨æˆ·éƒ½èƒ½ç†è§£è§£è¯»å†…å®¹
"""

from typing import Dict, Any, List, Optional
import re

class PlainLanguageConverter:
    """å¤§ç™½è¯è½¬æ¢å¼•æ“"""
    
    def __init__(self):
        # ä¸“ä¸šæœ¯è¯­åˆ°ç”Ÿæ´»è¯­è¨€çš„æ˜ å°„
        self.terminology_mapping = {
            # æ ¼å±€ç±»å‹
            "æ¯”è‚©æ—º": "å¤©ç”Ÿä¸æœè¾“ï¼Œå–œæ¬¢æŒæ§ä¸»åŠ¨æƒ",
            "åŠ«è´¢æ—º": "å›¢é˜Ÿåˆä½œèƒ½åŠ›å¼ºï¼Œä½†æœ‰æ—¶å®¹æ˜“ä¸äººç«äº‰",
            "å°é‡": "å®‰å…¨æ„Ÿéœ€æ±‚å¼ºï¼Œå–œæ¬¢ç¨³å®šå’Œè¢«è®¤å¯",
            "æ­£å°": "å­¦ä¹ èƒ½åŠ›å¼ºï¼Œå®¹æ˜“è·å¾—é•¿è¾ˆå–œçˆ±",
            "åå°": "æ€ç»´ç‹¬ç‰¹ï¼Œå–œæ¬¢å¦è¾Ÿè¹Šå¾„",
            "è´¢æ—º": "ç›®æ ‡å¯¼å‘ï¼Œå–„äºæŠŠæƒ³æ³•å˜æˆç°å®",
            "æ­£è´¢": "åšäº‹è¸å®ï¼Œè¿½æ±‚ç¨³å®šçš„æ”¶å…¥",
            "åè´¢": "æœºä¼šæ„è¯†å¼ºï¼Œæ•¢äºå†’é™©æŠ•èµ„",
            "ç…é‡": "è´£ä»»å¿ƒå¼ºï¼Œåœ¨å‹åŠ›ä¸‹åè€Œèƒ½å‘æŒ¥æ›´å¥½",
            "æ­£å®˜": "è§„åˆ™æ„è¯†å¼ºï¼Œé€‚åˆç¨³å®šçš„å·¥ä½œç¯å¢ƒ",
            "ä¸ƒæ€": "æ‰¿å‹èƒ½åŠ›å¼ºï¼Œé€‚åˆæœ‰æŒ‘æˆ˜çš„å·¥ä½œ",
            "ä¼¤å®˜æ—º": "åˆ›æ„åè¶³ï¼Œä¸å–œæ¬¢è¢«æ¡æ¡æ¡†æ¡†é™åˆ¶",
            "é£Ÿç¥": "æ€è€ƒèƒ½åŠ›å¼ºï¼Œå–„äºé•¿è¿œè§„åˆ’",
            
            # ç‰¹æ®Šæ ¼å±€
            "ä»è´¢": "å–„äºå€ŸåŠ›æ‰“åŠ›ï¼Œæ‡‚å¾—ä¸ç¯å¢ƒåˆä½œå…±èµ¢",
            "ä»æ€": "åœ¨è§„åˆ™å’Œçº¦æŸä¸­åè€Œèƒ½æ‰¾åˆ°è‡ªå·±çš„ä½ç½®",
            "ä»å°": "å­¦ä¹ èƒ½åŠ›è¶…å¼ºï¼Œå®¹æ˜“è·å¾—ä»–äººæ”¯æŒ",
            "ä»å„¿": "åˆ›é€ åŠ›ä¸°å¯Œï¼Œé€‚åˆè‡ªç”±å‘æŒ¥çš„ç¯å¢ƒ",
            "åŒ–æ°”æ ¼": "ä¸“æ³¨åŠ›å¼ºï¼Œå®¹æ˜“åœ¨æŸä¸ªé¢†åŸŸæ·±åº¦å‘å±•",
            "ä¸“æ—ºæ ¼": "æŸæ–¹é¢èƒ½åŠ›ç‰¹åˆ«çªå‡ºï¼Œä½†éœ€è¦å¹³è¡¡å‘å±•",
            "æ— æ ¹å±€": "çµæ´»æ€§å¼ºï¼Œä½†éœ€è¦æ‰¾åˆ°ç¨³å®šçš„æ”¯æ’‘",
            "è™šé€æ ¼": "æƒ³æ³•å¾ˆå¤šï¼Œä½†éœ€è¦åŠ å¼ºè¡ŒåŠ¨åŠ›",
            
            # å¼ºå¼±æè¿°
            "æ—º": "èƒ½é‡å……è¶³ï¼Œæ´»åŠ›æ»¡æ»¡",
            "å¼º": "åº•æ°”è¶³ï¼Œæœ‰è‡ªä¿¡",
            "å¼±": "æ¯”è¾ƒæ•æ„Ÿï¼Œéœ€è¦æ›´å¤šæ”¯æŒ",
            "ææ—º": "èƒ½é‡è¿‡ç››ï¼Œéœ€è¦é€‚å½“é‡Šæ”¾",
            "æå¼±": "èƒ½é‡ä¸è¶³ï¼Œéœ€è¦å¥½å¥½ä¼‘å…»",
            
            # äº”è¡Œå…ƒç´ 
            "æœ¨æ—º": "ç”Ÿå‘½åŠ›æ—ºç››ï¼Œæ€»æƒ³å°è¯•æ–°äº‹ç‰©",
            "ç«æ—º": "çƒ­æƒ…æ´‹æº¢ï¼Œå¾ˆæœ‰æ„ŸæŸ“åŠ›",
            "åœŸæ—º": "è¸å®ç¨³é‡ï¼Œè®©äººæœ‰å®‰å…¨æ„Ÿ",
            "é‡‘æ—º": "åŸåˆ™æ€§å¼ºï¼Œåšäº‹æœ‰æ¡ç†",
            "æ°´æ—º": "èªæ˜çµæ´»ï¼Œé€‚åº”èƒ½åŠ›å¼º",
            
            # è°ƒå€™æè¿°
            "å¯’é‡": "å†…å¿ƒæ¯”è¾ƒå®‰é™ï¼Œéœ€è¦æ›´å¤šæ¸©æš–å’Œæ¿€åŠ±",
            "ç‡¥é‡": "å®¹æ˜“æ€¥èºï¼Œéœ€è¦ä¿æŒå†…å¿ƒå¹³é™",
            "åå¯’": "æœ‰æ—¶å€™ç¼ºä¹è¡ŒåŠ¨åŠ›ï¼Œéœ€è¦é€‚å½“çš„æ¨åŠ¨",
            "åç‡¥": "æœ‰æ—¶å€™æ¯”è¾ƒæ€¥æ€§å­ï¼Œéœ€è¦å­¦ä¼šè€å¿ƒ",
            "å¹³å’Œ": "æ€§æ ¼æ¯”è¾ƒæ¸©å’Œï¼Œèƒ½é‡ç›¸å¯¹å¹³è¡¡",
            
            # æ ¹çš„çŠ¶æ€
            "æœ‰æ˜æ ¹": "åŸºç¡€å¾ˆæ‰å®ï¼Œæœ‰ç¨³å®šçš„æ”¯æ’‘",
            "æœ‰è—æ ¹": "è™½ç„¶è¡¨é¢çœ‹ä¸å‡ºæ¥ï¼Œä½†å†…åœ¨å¾ˆæœ‰å®åŠ›",
            "æ— æ ¹": "æ¯”è¾ƒçµæ´»ï¼Œä½†éœ€è¦å¤–ç•Œçš„æ”¯æŒ",
            
            # æ‰¶æŠ‘å…³ç³»  
            "æ‰¶æŠ‘æ ¼": "éœ€è¦å¹³è¡¡å‘å±•ï¼Œæ—¢è¦å‘æŒ¥ä¼˜åŠ¿ä¹Ÿè¦è¡¥è¶³ä¸è¶³",
            "ä»æ ¼": "é¡ºåŠ¿è€Œä¸ºï¼Œå€ŸåŠ©å¤–åŠ›å‘å±•",
            "åŒ–æ ¼": "ä¸“æ³¨äºæŸä¸ªæ–¹å‘æ·±åº¦å‘å±•"
        }
        
        # ç”Ÿæ´»åœºæ™¯æ˜ å°„
        self.life_scenarios = {
            "æ¯”è‚©æ—º": [
                "åœ¨å›¢é˜Ÿä¼šè®®ä¸Šï¼Œæ‚¨æ€»æ˜¯é‚£ä¸ªæå‡ºä¸åŒæ„è§çš„äºº",
                "åšå†³å®šæ—¶ï¼Œæ‚¨æ›´ç›¸ä¿¡è‡ªå·±çš„åˆ¤æ–­è€Œä¸æ˜¯å¤§ä¼—çš„é€‰æ‹©",
                "æœ‹å‹æ‰¾æ‚¨å•†é‡äº‹æƒ…ï¼Œå› ä¸ºæ‚¨æ•¢è¯´çœŸè¯"
            ],
            "å°é‡": [
                "æ‚¨å–œæ¬¢æŠŠäº‹æƒ…ç ”ç©¶é€å½»äº†å†è¡ŒåŠ¨",
                "è´­ä¹°ä¸œè¥¿å‰ä¼šçœ‹å¾ˆå¤šè¯„ä»·å’Œæ”»ç•¥",
                "é‡åˆ°é—®é¢˜æ—¶ä¹ æƒ¯å…ˆå’¨è¯¢ä¸“å®¶æˆ–æŸ¥èµ„æ–™"
            ],
            "è´¢æ—º": [
                "æ‚¨åšä»»ä½•äº‹éƒ½ä¼šå…ˆè€ƒè™‘è¿™èƒ½å¸¦æ¥ä»€ä¹ˆæ”¶è·",
                "æ‚¨å¾ˆå–„äºå‘ç°ç”Ÿæ´»ä¸­çš„å•†æœºå’Œæœºä¼š",
                "æ‚¨çš„æœ‹å‹éƒ½è§‰å¾—æ‚¨å¾ˆæœ‰ç”Ÿæ„å¤´è„‘"
            ],
            "ç…é‡": [
                "æ‚¨æ˜¯é‚£ç§'ç­”åº”äº†å°±ä¸€å®šè¦åšåˆ°'çš„äºº",
                "åœ¨ç´§æ€¥æƒ…å†µä¸‹ï¼Œå¤§å®¶éƒ½ä¼šæƒ³åˆ°æ‚¨",
                "æ‚¨å¯¹è‡ªå·±å’Œä»–äººéƒ½æœ‰æ¯”è¾ƒé«˜çš„æ ‡å‡†"
            ],
            "ä¼¤å®˜æ—º": [
                "æ‚¨æ€»æœ‰å¾ˆå¤šæ–°å¥‡çš„æƒ³æ³•å’Œåˆ›æ„",
                "æ‚¨ä¸å–œæ¬¢æŒ‰ç…§å›ºå®šçš„æ¨¡å¼åšäº‹",
                "æ‚¨å¸Œæœ›èƒ½ç”¨è‡ªå·±çš„æ–¹å¼è¡¨è¾¾å’Œåˆ›é€ "
            ]
        }
        
        # å¿ƒç†çŠ¶æ€æè¿°
        self.psychological_descriptions = {
            "ç„¦è™‘å‹": "æ‚¨å®¹æ˜“ä¸ºæœªæ¥æ‹…å¿ƒï¼Œæ€»æƒ³æŠŠæ‰€æœ‰å¯èƒ½çš„é£é™©éƒ½è€ƒè™‘åˆ°",
            "è¡ŒåŠ¨å‹": "æ‚¨æ˜¯æƒ³åˆ°å°±è¦å»åšçš„äººï¼Œä¸å–œæ¬¢æ‹–å»¶å’ŒçŠ¹è±«",
            "æ€è€ƒå‹": "æ‚¨å–œæ¬¢æŠŠé—®é¢˜æƒ³æ¸…æ¥šï¼Œè®¤ä¸ºå……åˆ†çš„æ€è€ƒæ¯”åŒ†å¿™çš„è¡ŒåŠ¨æ›´é‡è¦",
            "æ„Ÿå—å‹": "æ‚¨å¾ˆæ•æ„Ÿï¼Œèƒ½æ„Ÿå—åˆ°åˆ«äººå¯Ÿè§‰ä¸åˆ°çš„ç»†å¾®å˜åŒ–",
            "ç›®æ ‡å‹": "æ‚¨æ˜¯æœ‰æ˜ç¡®ç›®æ ‡çš„äººï¼Œå–œæ¬¢çœ‹åˆ°è‡ªå·±çš„è¿›æ­¥å’Œæˆæœ"
        }
    
    def convert_to_plain_language(self, technical_analysis: Dict[str, Any]) -> Dict[str, str]:
        """å°†æŠ€æœ¯åˆ†æè½¬æ¢ä¸ºå¤§ç™½è¯"""
        converted = {}
        
        # è½¬æ¢æ ¼å±€åˆ†æ
        if "å®šæ ¼å±€" in technical_analysis:
            converted["æ ¼å±€è¯´æ˜"] = self._convert_geju_analysis(technical_analysis["å®šæ ¼å±€"])
        
        # è½¬æ¢äº”è¡Œåˆ†æ
        if "äº”è¡Œç»Ÿè®¡" in technical_analysis:
            converted["äº”è¡Œè¯´æ˜"] = self._convert_wuxing_analysis(technical_analysis["äº”è¡Œç»Ÿè®¡"])
        
        # è½¬æ¢ç—…è¯åˆ†æ
        if "å®šç—…è¯" in technical_analysis:
            converted["ç—…è¯è¯´æ˜"] = self._convert_bingyao_analysis(technical_analysis["å®šç—…è¯"])
        
        # è½¬æ¢è°ƒå€™åˆ†æ
        if "å®šå¯’ç‡¥" in technical_analysis:
            converted["è°ƒå€™è¯´æ˜"] = self._convert_hanzao_analysis(technical_analysis["å®šå¯’ç‡¥"])
        
        # è½¬æ¢å¤§è¿åˆ†æ
        if "çœ‹å¤§è¿" in technical_analysis:
            converted["å¤§è¿è¯´æ˜"] = self._convert_dayun_analysis(technical_analysis["çœ‹å¤§è¿"])
        
        return converted
    
    def _convert_geju_analysis(self, geju_data: Dict[str, Any]) -> str:
        """è½¬æ¢æ ¼å±€åˆ†æä¸ºå¤§ç™½è¯"""
        geju_type = geju_data.get("æ ¼å±€ç±»å‹", "")
        strength = geju_data.get("å¼ºå¼±", "")
        root_status = geju_data.get("æ ¹", "")
        
        plain_description = []
        
        # åŸºç¡€æ ¼å±€è½¬æ¢
        if geju_type in self.terminology_mapping:
            basic_desc = self.terminology_mapping[geju_type]
            plain_description.append(f"æ‚¨çš„æ€§æ ¼ç‰¹ç‚¹ï¼š{basic_desc}")
        
        # å¼ºå¼±è½¬æ¢
        strength_descriptions = {
            "æ—º": "æ‚¨è¿™æ–¹é¢çš„èƒ½é‡å¾ˆå……è¶³ï¼Œæ˜¯æ‚¨çš„ä¼˜åŠ¿æ‰€åœ¨",
            "å¼º": "æ‚¨åœ¨è¿™æ–¹é¢æ¯”è¾ƒæœ‰åº•æ°”å’Œè‡ªä¿¡",
            "å¼±": "æ‚¨è¿™æ–¹é¢æ¯”è¾ƒæ•æ„Ÿï¼Œéœ€è¦æ›´å¤šçš„æ”¯æŒå’Œé¼“åŠ±",
            "ææ—º": "æ‚¨è¿™æ–¹é¢çš„èƒ½é‡éå¸¸å¼ºï¼Œä½†ä¹Ÿè¦æ³¨æ„ä¸è¦è¿‡çŠ¹ä¸åŠ",
            "æå¼±": "æ‚¨è¿™æ–¹é¢éœ€è¦ç‰¹åˆ«çš„å…³æ³¨å’ŒåŸ¹å…»"
        }
        
        if strength in strength_descriptions:
            plain_description.append(strength_descriptions[strength])
        
        # æ ¹çš„çŠ¶æ€è½¬æ¢
        root_descriptions = {
            "æœ‰æ˜æ ¹": "æ‚¨çš„åŸºç¡€å¾ˆæ‰å®ï¼Œåšäº‹æœ‰åº•æ°”",
            "æœ‰è—æ ¹": "è™½ç„¶è¡¨é¢çœ‹èµ·æ¥æ¸©å’Œï¼Œä½†å†…åœ¨å¾ˆæœ‰å®åŠ›",
            "æ— æ ¹": "æ‚¨å¾ˆçµæ´»ï¼Œä½†éœ€è¦æ‰¾åˆ°ç¨³å®šçš„æ”¯æ’‘ç‚¹"
        }
        
        if root_status in root_descriptions:
            plain_description.append(root_descriptions[root_status])
        
        return "ã€‚".join(plain_description) + "ã€‚"
    
    def _convert_wuxing_analysis(self, wuxing_data: Dict[str, Any]) -> str:
        """è½¬æ¢äº”è¡Œåˆ†æä¸ºå¤§ç™½è¯"""
        strongest = wuxing_data.get("æœ€æ—º", "")
        weakest = wuxing_data.get("æœ€å¼±", "")
        
        element_personalities = {
            "æœ¨": "æ‚¨æœ‰å¾ˆå¼ºçš„æˆé•¿æ¬²æœ›ï¼Œæ€»æƒ³å°è¯•æ–°äº‹ç‰©ï¼Œä¸å–œæ¬¢ä¸€æˆä¸å˜",
            "ç«": "æ‚¨å¾ˆæœ‰çƒ­æƒ…å’Œæ„ŸæŸ“åŠ›ï¼Œå®¹æ˜“å¸¦åŠ¨å‘¨å›´çš„æ°”æ°›ï¼Œä½†æœ‰æ—¶å¯èƒ½æœ‰ç‚¹æ€¥æ€§å­",
            "åœŸ": "æ‚¨å¾ˆè¸å®å¯é ï¼Œæœ‹å‹éƒ½å–œæ¬¢æ‰¾æ‚¨å•†é‡äº‹æƒ…ï¼Œä½†æœ‰æ—¶å¯èƒ½æœ‰ç‚¹ä¿å®ˆ",
            "é‡‘": "æ‚¨åšäº‹å¾ˆæœ‰åŸåˆ™å’Œæ¡ç†ï¼Œè¿½æ±‚å®Œç¾å’Œæ•ˆç‡ï¼Œä½†æœ‰æ—¶å¯èƒ½æœ‰ç‚¹ä¸¥æ ¼",
            "æ°´": "æ‚¨å¾ˆèªæ˜çµæ´»ï¼Œå–„äºè§‚å¯Ÿå’Œæ€è€ƒï¼Œä½†æœ‰æ—¶å¯èƒ½æƒ³å¾—å¤ªå¤š"
        }
        
        descriptions = []
        
        if strongest:
            element_clean = strongest.replace("å…ƒç´ ", "")
            if element_clean in element_personalities:
                descriptions.append(f"æ‚¨æœ€çªå‡ºçš„ç‰¹è´¨ï¼š{element_personalities[element_clean]}")
        
        if weakest and weakest != strongest:
            element_clean = weakest.replace("å…ƒç´ ", "")
            weakness_descriptions = {
                "æœ¨": "æœ‰æ—¶å€™å¯èƒ½ç¼ºä¹æˆé•¿çš„åŠ¨åŠ›ï¼Œéœ€è¦å¤šç»™è‡ªå·±ä¸€äº›æ–°çš„åˆºæ¿€",
                "ç«": "æœ‰æ—¶å€™å¯èƒ½ä¸å¤Ÿæœ‰æ¿€æƒ…ï¼Œéœ€è¦å¤šæ¥è§¦æ­£èƒ½é‡çš„äººå’Œäº‹",
                "åœŸ": "æœ‰æ—¶å€™å¯èƒ½ä¸å¤Ÿè¸å®ï¼Œéœ€è¦å¤šåŸ¹å…»è€å¿ƒå’ŒåšæŒ",
                "é‡‘": "æœ‰æ—¶å€™å¯èƒ½ä¸å¤Ÿæœ‰åŸåˆ™ï¼Œéœ€è¦å¤šåŸ¹å…»è‡ªå·±çš„åº•çº¿å’Œæ ‡å‡†",
                "æ°´": "æœ‰æ—¶å€™å¯èƒ½ä¸å¤Ÿçµæ´»ï¼Œéœ€è¦å¤šåŸ¹å…»å˜é€šçš„æ™ºæ…§"
            }
            if element_clean in weakness_descriptions:
                descriptions.append(f"éœ€è¦æ³¨æ„çš„æ–¹é¢ï¼š{weakness_descriptions[element_clean]}")
        
        return "ã€‚".join(descriptions) + "ã€‚"
    
    def _convert_bingyao_analysis(self, bingyao_data: Dict[str, Any]) -> str:
        """è½¬æ¢ç—…è¯åˆ†æä¸ºå¤§ç™½è¯"""
        if not bingyao_data.get("åˆ†çº§"):
            return "æš‚æ— ç—…è¯åˆ†æç»“æœã€‚"
        
        first_level = bingyao_data["åˆ†çº§"][0]
        pattern_type = first_level.get("å‘½å±€ç±»å‹", "")
        medicine_config = first_level.get("ç—…è¯é…ç½®", {})
        
        descriptions = []
        
        # å‘½å±€ç±»å‹è¯´æ˜
        if pattern_type in self.terminology_mapping:
            descriptions.append(f"æ‚¨çš„èƒ½é‡æ¨¡å¼ï¼š{self.terminology_mapping[pattern_type]}")
        
        # ç”¨è¯è¯´æ˜ï¼ˆè½¬æ¢ä¸ºæ„è¯†å»ºè®®ï¼‰
        medicine_explanations = {
            "å›è¯": "æœ€é‡è¦çš„æ˜¯",
            "è‡£è¯": "å…¶æ¬¡éœ€è¦", 
            "æ¬¡è¯": "ä¹Ÿå¯ä»¥è€ƒè™‘"
        }
        
        for medicine_level, medicine_name in medicine_config.items():
            if medicine_level in medicine_explanations and medicine_name:
                plain_medicine = self.terminology_mapping.get(medicine_name, medicine_name)
                action_verb = medicine_explanations[medicine_level]
                descriptions.append(f"{action_verb}åŸ¹å…»{plain_medicine}çš„å“è´¨")
        
        return "ã€‚".join(descriptions) + "ã€‚"
    
    def _convert_hanzao_analysis(self, hanzao_data: Dict[str, Any]) -> str:
        """è½¬æ¢å¯’ç‡¥åˆ†æä¸ºå¤§ç™½è¯"""
        climate_type = hanzao_data.get("ç±»å‹", "")
        need_element = hanzao_data.get("éœ€è¦è°ƒå€™", "")
        
        climate_descriptions = {
            "å¯’é‡": "æ‚¨çš„æ€§æ ¼æ¯”è¾ƒå†…æ•›æ²‰é™ï¼Œä½†æœ‰æ—¶å€™å¯èƒ½ç¼ºä¹è¡ŒåŠ¨çš„çƒ­æƒ…",
            "ç‡¥é‡": "æ‚¨çš„æ€§æ ¼æ¯”è¾ƒæ€¥èºæ´»è·ƒï¼Œä½†æœ‰æ—¶å€™éœ€è¦ä¿æŒå†…å¿ƒçš„å¹³é™",
            "åå¯’": "æ‚¨å¤§éƒ¨åˆ†æ—¶å€™æ¯”è¾ƒæ¸©å’Œï¼Œä½†æœ‰æ—¶å€™éœ€è¦ä¸€äº›å¤–åœ¨çš„æ¿€åŠ±",
            "åç‡¥": "æ‚¨å¤§éƒ¨åˆ†æ—¶å€™æ¯”è¾ƒæœ‰æ´»åŠ›ï¼Œä½†æœ‰æ—¶å€™éœ€è¦å­¦ä¼šæ…¢ä¸‹æ¥",
            "å¹³å’Œ": "æ‚¨çš„æ€§æ ¼æ¯”è¾ƒæ¸©å’Œå¹³è¡¡ï¼Œè¿™æ˜¯å¾ˆå¥½çš„ç‰¹è´¨"
        }
        
        base_desc = climate_descriptions.get(climate_type, "æ‚¨æœ‰ç€ç‹¬ç‰¹çš„æ€§æ ¼ç‰¹è´¨")
        
        # è°ƒå€™å»ºè®®è½¬æ¢
        adjustment_advice = {
            "fire": "å»ºè®®å¤šæ¥è§¦é˜³å…‰ã€è¿åŠ¨ã€çƒ­æƒ…çš„äººå’Œäº‹ï¼Œç»™è‡ªå·±å¢åŠ ä¸€äº›æ´»åŠ›",
            "water": "å»ºè®®å¤šåœ¨å®‰é™çš„ç¯å¢ƒä¸­æ€è€ƒï¼Œä¿æŒå†…å¿ƒçš„å®é™å’Œæ·±åº¦",
            "wood": "å»ºè®®å¤šæ¥è§¦è‡ªç„¶ï¼Œç»™è‡ªå·±ä¸€äº›æˆé•¿å’Œå­¦ä¹ çš„æœºä¼š",
            "metal": "å»ºè®®åŸ¹å…»ä¸€äº›è§„å¾‹æ€§çš„ä¹ æƒ¯ï¼Œè®©è‡ªå·±æ›´æœ‰æ¡ç†",
            "earth": "å»ºè®®ä¿æŒè„šè¸å®åœ°çš„æ€åº¦ï¼Œä¸€æ­¥ä¸€ä¸ªè„šå°åœ°å‰è¿›"
        }
        
        advice = adjustment_advice.get(need_element, "ä¿æŒç°åœ¨çš„çŠ¶æ€å°±å¾ˆå¥½")
        
        return f"{base_desc}ã€‚{advice}ã€‚"
    
    def _convert_dayun_analysis(self, dayun_data: Dict[str, Any]) -> str:
        """è½¬æ¢å¤§è¿åˆ†æä¸ºå¤§ç™½è¯"""
        current_dayun = dayun_data.get("å½“å‰å¤§è¿", {})
        future_dayuns = dayun_data.get("æœªæ¥å¤§è¿", [])
        
        if not current_dayun:
            return "æš‚æ— å¤§è¿åˆ†æä¿¡æ¯ã€‚"
        
        age_range = current_dayun.get("age_range", "")
        influence = current_dayun.get("influence", "")
        
        descriptions = []
        descriptions.append(f"æ‚¨ç°åœ¨{age_range}å²è¿™ä¸ªé˜¶æ®µï¼š{influence}")
        
        # æœªæ¥å¤§è¿çš„ç®€å•è¯´æ˜
        if future_dayuns:
            next_dayun = future_dayuns[0]
            next_age = next_dayun.get("age_range", "")
            next_influence = next_dayun.get("influence", "")
            descriptions.append(f"åˆ°äº†{next_age}å²å·¦å³ï¼š{next_influence}")
        
        # æ·»åŠ é€šç”¨çš„æ—¶æœºæŠŠæ¡å»ºè®®
        timing_advice = [
            "æ¯ä¸ªäººç”Ÿé˜¶æ®µéƒ½æœ‰ä¸åŒçš„é‡ç‚¹ï¼Œå…³é”®æ˜¯è¦é¡ºåº”è‡ªå·±çš„å†…åœ¨èŠ‚å¥",
            "é‡è¦çš„ä¸æ˜¯æŠ¢åœ¨åˆ«äººå‰é¢ï¼Œè€Œæ˜¯åœ¨åˆé€‚çš„æ—¶å€™åšåˆé€‚çš„äº‹"
        ]
        
        descriptions.extend(timing_advice[:1])
        
        return "ã€‚".join(descriptions) + "ã€‚"
    
    def simplify_consciousness_description(self, consciousness_text: str) -> str:
        """ç®€åŒ–æ„è¯†æè¿°ä¸ºç”Ÿæ´»è¯­è¨€"""
        # æ›¿æ¢å¤æ‚çš„å¿ƒç†å­¦æœ¯è¯­
        replacements = {
            "æ„è¯†å“è´¨": "æ€§æ ¼ç‰¹ç‚¹",
            "èƒ½é‡æ¨¡å¼": "è¡Œä¸ºæ–¹å¼",
            "å†…åœ¨é©±åŠ¨": "å†…å¿ƒæƒ³æ³•",
            "å¤–åœ¨è¡¨ç°": "å¹³æ—¶è¡¨ç°",
            "å¿ƒç†æœºåˆ¶": "å¿ƒç†çŠ¶æ€",
            "è®¤çŸ¥æ¨¡å¼": "æ€ç»´æ–¹å¼",
            "è¡Œä¸ºå€¾å‘": "åšäº‹ä¹ æƒ¯",
            "æƒ…ç»ªç‰¹è´¨": "æƒ…ç»ªè¡¨ç°",
            "ç¤¾äº¤æ¨¡å¼": "ä¸äººç›¸å¤„çš„æ–¹å¼",
            "å†³ç­–é£æ ¼": "åšå†³å®šçš„ä¹ æƒ¯"
        }
        
        simplified_text = consciousness_text
        for technical, plain in replacements.items():
            simplified_text = simplified_text.replace(technical, plain)
        
        return simplified_text
    
    def add_life_examples(self, abstract_description: str, user_context: Dict[str, Any]) -> str:
        """ä¸ºæŠ½è±¡æè¿°æ·»åŠ ç”Ÿæ´»å®ä¾‹"""
        # æ ¹æ®ç”¨æˆ·ä¸Šä¸‹æ–‡æ·»åŠ å…·ä½“çš„ç”Ÿæ´»åœºæ™¯
        age = user_context.get("age", 25)
        gender = user_context.get("gender", "")
        question_category = user_context.get("question_category", "")
        
        # å¹´é¾„æ®µç‰¹å®šçš„ä¾‹å­
        age_examples = {
            "young": "æ¯”å¦‚åœ¨é€‰æ‹©ä¸“ä¸šã€æ‰¾å·¥ä½œã€è°ˆæ‹çˆ±æ—¶",
            "middle": "æ¯”å¦‚åœ¨èŒä¸šå‘å±•ã€å®¶åº­è§„åˆ’ã€æŠ•èµ„ç†è´¢æ—¶", 
            "mature": "æ¯”å¦‚åœ¨äº‹ä¸šè½¬å‹ã€å­å¥³æ•™è‚²ã€å¥åº·ç®¡ç†æ—¶"
        }
        
        if age < 30:
            age_context = age_examples["young"]
        elif age < 50:
            age_context = age_examples["middle"]
        else:
            age_context = age_examples["mature"]
        
        # ä¸ºæè¿°æ·»åŠ å…·ä½“æƒ…å¢ƒ
        if "æ‚¨" in abstract_description and age_context:
            enhanced_description = abstract_description.replace(
                "æ‚¨", f"æ‚¨ï¼ˆ{age_context}ï¼‰", 1
            )
            return enhanced_description
        
        return abstract_description
    
    def format_final_interpretation(self, all_sections: Dict[str, str], user_context: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆè§£è¯»ç»“æœ"""
        output_parts = []
        
        # æ ‡é¢˜
        user_name = user_context.get("name", "æ‚¨")
        output_parts.append(f"## ğŸ“Š {user_name}çš„èƒ½é‡è§£è¯»æŠ¥å‘Š")
        output_parts.append("")
        
        # å„éƒ¨åˆ†å†…å®¹æŒ‰ä¼˜å…ˆçº§æ’åˆ—
        section_order = [
            ("å…«å­—åŸºæœ¬ä¿¡æ¯", "bazi_info"),
            ("æ‚¨çš„èƒ½é‡ç”»åƒ", "energy_portrait"),
            ("å…³äºæ‚¨çš„é—®é¢˜", "question_analysis"),
            ("ç ´è§£çš„å…³é”®", "solution_key"),
            ("æ›´æ·±å±‚çš„æ€è€ƒ", "deeper_reflection"),
            ("å…·ä½“å»ºè®®", "actionable_advice"),
            ("æ—¶æœºæŠŠæ¡", "timing_guidance"),
            ("èƒ½é‡è°ƒèŠ‚", "energy_management")
        ]
        
        for title, section_key in section_order:
            if section_key in all_sections and all_sections[section_key]:
                output_parts.append(f"### {title}")
                content = all_sections[section_key]
                # ç¡®ä¿å†…å®¹æ˜¯å¤§ç™½è¯
                simplified_content = self.simplify_consciousness_description(content)
                enhanced_content = self.add_life_examples(simplified_content, user_context)
                output_parts.append(enhanced_content)
                output_parts.append("")
        
        # ç»“è¯­
        output_parts.append("---")
        output_parts.append("ğŸ’ **æ¸©é¦¨æé†’**ï¼šè¿™ä»½è§£è¯»æ˜¯åŸºäºä¼ ç»Ÿå‘½ç†å­¦çš„åˆ†ææ¡†æ¶ï¼Œç›®çš„æ˜¯å¸®åŠ©æ‚¨æ›´å¥½åœ°äº†è§£è‡ªå·±ï¼Œä¸ºäººç”Ÿå†³ç­–æä¾›å‚è€ƒã€‚æ¯ä¸ªäººéƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„ï¼Œæœ€ç»ˆçš„é€‰æ‹©æƒå§‹ç»ˆåœ¨æ‚¨è‡ªå·±æ‰‹ä¸­ã€‚")
        
        return "\n".join(output_parts)
    
    def extract_key_messages(self, full_interpretation: str) -> List[str]:
        """æå–å…³é”®ä¿¡æ¯ç‚¹"""
        # ä½¿ç”¨ç®€å•çš„è§„åˆ™æå–é‡è¦ä¿¡æ¯
        key_patterns = [
            r"æ‚¨çš„æ ¸å¿ƒç‰¹è´¨[ï¼š:](.+?)[\ã€‚\.]",
            r"æœ€é‡è¦çš„æ˜¯(.+?)[\ã€‚\.]", 
            r"å…³é”®åœ¨äº(.+?)[\ã€‚\.]",
            r"å»ºè®®æ‚¨(.+?)[\ã€‚\.]"
        ]
        
        key_messages = []
        for pattern in key_patterns:
            matches = re.findall(pattern, full_interpretation)
            key_messages.extend(matches[:2])  # æ¯ä¸ªæ¨¡å¼æœ€å¤šå–2ä¸ª
        
        return key_messages[:5]  # æ€»å…±æœ€å¤š5ä¸ªå…³é”®ä¿¡æ¯